{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yUIV6ye3uyc0"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load data into pandas dataframe\n",
        "url = 'https://raw.githubusercontent.com/scrannad/Medicare-Project/annas_branch/numeric_only.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.head(25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "6sjPRW7ozVcW",
        "outputId": "36bc7f96-3f3e-460e-8d7a-a48676b7e683"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Beneficiaries_with_A_and_B  Fee_for_service_beneficiaries  \\\n",
              "0                         6444                           6186   \n",
              "1                         7463                           6861   \n",
              "2                        14583                          13311   \n",
              "3                        18984                          17907   \n",
              "4                         6134                           5925   \n",
              "5                         5256                           4734   \n",
              "6                       100102                          93339   \n",
              "7                        11777                          10945   \n",
              "8                       111879                         104284   \n",
              "9                         6065                           2703   \n",
              "10                       21767                          13018   \n",
              "11                        3549                           2056   \n",
              "12                       19330                          10717   \n",
              "13                       12533                           6169   \n",
              "14                        7733                           4262   \n",
              "15                       10078                           4869   \n",
              "16                        4638                           3032   \n",
              "17                       14132                           6932   \n",
              "18                        6909                           4838   \n",
              "19                       16186                           8377   \n",
              "20                        7742                           3280   \n",
              "21                       12759                           6528   \n",
              "22                        8830                           4072   \n",
              "23                       44755                          21446   \n",
              "24                       10474                           6856   \n",
              "\n",
              "    Med_Advantage_Count  Med_Advantage_Rate  Average_Age  %Female   %Male  \\\n",
              "0                   258              0.0400           71   0.5144  0.4856   \n",
              "1                   602              0.0807           73   0.5270  0.4730   \n",
              "2                  1272              0.0872           71   0.5330  0.4670   \n",
              "3                  1077              0.0567           72   0.5456  0.4544   \n",
              "4                   209              0.0341           70   0.5232  0.4768   \n",
              "5                   522              0.0993           72   0.5239  0.4761   \n",
              "6                  6763              0.0676           74   0.5273  0.4727   \n",
              "7                   832              0.0706           52   0.4838  0.5162   \n",
              "8                  7595              0.0679           72   0.5227  0.4773   \n",
              "9                  3362              0.5543           67   0.4639  0.5361   \n",
              "10                 8749              0.4019           71   0.5380  0.4620   \n",
              "11                 1493              0.4207           71   0.5233  0.4767   \n",
              "12                 8613              0.4456           70   0.5289  0.4711   \n",
              "13                 6364              0.5078           71   0.5325  0.4675   \n",
              "14                 3471              0.4489           72   0.5178  0.4822   \n",
              "15                 5209              0.5169           72   0.5371  0.4629   \n",
              "16                 1606              0.3463           72   0.5310  0.4690   \n",
              "17                 7200              0.5095           72   0.5365  0.4635   \n",
              "18                 2071              0.2998           72   0.5308  0.4692   \n",
              "19                 7809              0.4825           70   0.5275  0.4725   \n",
              "20                 4462              0.5763           71   0.5345  0.4655   \n",
              "21                 6231              0.4884           72   0.5415  0.4585   \n",
              "22                 4758              0.5388           67   0.5091  0.4909   \n",
              "23                23309              0.5208           71   0.5356  0.4644   \n",
              "24                 3618              0.3454           72   0.5492  0.4508   \n",
              "\n",
              "    %White  %Black  %Hispanic  ...  Dialysis_User_Count  Dialysis_User_%  \\\n",
              "0   0.8810  0.0063     0.0833  ...                   40           0.0065   \n",
              "1   0.9469  0.0020     0.0144  ...                   19           0.0028   \n",
              "2   0.9246  0.0072     0.0336  ...                   74           0.0056   \n",
              "3   0.8645  0.0168     0.0782  ...                   86           0.0048   \n",
              "4   0.9391  0.0025     0.0253  ...                   38           0.0064   \n",
              "5   0.8925  0.0055     0.0606  ...                   18           0.0038   \n",
              "6   0.9182  0.0040     0.0373  ...                  247           0.0026   \n",
              "7   0.8429  0.0170     0.0744  ...                  209           0.0191   \n",
              "8   0.9103  0.0053     0.0412  ...                  456           0.0044   \n",
              "9   0.9811  0.0070     0.0041  ...                   29           0.0107   \n",
              "10  0.9694  0.0097     0.0030  ...                   71           0.0055   \n",
              "11  0.9747  0.0112     0.0054  ...                   13           0.0063   \n",
              "12  0.9244  0.0522     0.0062  ...                   80           0.0075   \n",
              "13  0.9752  0.0055     0.0029  ...                   59           0.0096   \n",
              "14  0.9763  0.0028     0.0028  ...                   30           0.0070   \n",
              "15  0.9417  0.0253     0.0051  ...                   27           0.0055   \n",
              "16  0.9631  0.0053     0.0059  ...                   14           0.0046   \n",
              "17  0.9375  0.0238     0.0065  ...                   44           0.0063   \n",
              "18  0.9554  0.0263     0.0035  ...                   20           0.0041   \n",
              "19  0.9348  0.0464     0.0032  ...                   68           0.0081   \n",
              "20  0.9759  0.0049     0.0076  ...                   17           0.0052   \n",
              "21  0.9521  0.0268     0.0058  ...                   57           0.0087   \n",
              "22  0.9683  0.0187     0.0034  ...                   32           0.0079   \n",
              "23  0.9225  0.0512     0.0039  ...                  180           0.0084   \n",
              "24  0.8995  0.0521     0.0166  ...                   65           0.0095   \n",
              "\n",
              "    Dialysis_Visits_Per_1000_Users  FQHC_Std_Costs  FQHC_Std_As_%Total  \\\n",
              "0                              741       330449.22              0.0068   \n",
              "1                              437        37418.97              0.0007   \n",
              "2                              665      1257134.97              0.0100   \n",
              "3                              554      1058899.69              0.0063   \n",
              "4                              659        69716.25              0.0013   \n",
              "5                              481       111911.30              0.0027   \n",
              "6                              327     10000026.42              0.0122   \n",
              "7                             2238      1870255.00              0.0156   \n",
              "8                              527     11870281.41              0.0127   \n",
              "9                             1118      1023021.51              0.0388   \n",
              "10                             723       397691.08              0.0027   \n",
              "11                             754       861028.35              0.0420   \n",
              "12                             834      2629192.73              0.0236   \n",
              "13                            1071       622392.29              0.0097   \n",
              "14                             954       251256.47              0.0056   \n",
              "15                             564         9917.93              0.0002   \n",
              "16                             570       718254.67              0.0264   \n",
              "17                             762       114978.65              0.0015   \n",
              "18                             398       692218.57              0.0132   \n",
              "19                             929      1651757.50              0.0206   \n",
              "20                             744         8027.65              0.0002   \n",
              "21                            1183       647465.25              0.0086   \n",
              "22                             818      1106000.31              0.0241   \n",
              "23                             933      1809829.18              0.0081   \n",
              "24                            1200       288231.62              0.0045   \n",
              "\n",
              "    FQHC_Std_Per_Capita  FQHC_Std_Per_User  FQHC_User_Count  FQHC_User_%  \\\n",
              "0                 53.42             306.26             1079       0.1744   \n",
              "1                  5.45             558.49               67       0.0098   \n",
              "2                 94.44             554.54             2267       0.1703   \n",
              "3                 59.13             605.43             1749       0.0977   \n",
              "4                 11.77             400.67              174       0.0294   \n",
              "5                 23.64             592.12              189       0.0399   \n",
              "6                107.14             625.00            16000       0.1714   \n",
              "7                170.88             704.69             2654       0.2425   \n",
              "8                113.83             636.34            18654       0.1789   \n",
              "9                378.48             596.86             1714       0.6341   \n",
              "10                30.55             467.32              851       0.0654   \n",
              "11               418.79             702.31             1226       0.5963   \n",
              "12               245.33             526.68             4992       0.4658   \n",
              "13               100.89             543.10             1146       0.1858   \n",
              "14                58.95             483.19              520       0.1220   \n",
              "15                 2.04             413.25               24       0.0049   \n",
              "16               236.89             680.81             1055       0.3480   \n",
              "17                16.59             438.85              262       0.0378   \n",
              "18               143.08             573.50             1207       0.2495   \n",
              "19               197.18             484.81             3407       0.4067   \n",
              "20                 2.45             334.49               24       0.0073   \n",
              "21                99.18             554.34             1168       0.1789   \n",
              "22               271.61             637.46             1735       0.4261   \n",
              "23                84.39             504.27             3589       0.1674   \n",
              "24                42.04             292.32              986       0.1438   \n",
              "\n",
              "    FQHC_Visits_Per_1000_Users  \n",
              "0                          553  \n",
              "1                           39  \n",
              "2                          773  \n",
              "3                          387  \n",
              "4                           86  \n",
              "5                          170  \n",
              "6                          652  \n",
              "7                         1164  \n",
              "8                          706  \n",
              "9                         4074  \n",
              "10                         220  \n",
              "11                        3121  \n",
              "12                        1754  \n",
              "13                         737  \n",
              "14                         429  \n",
              "15                          14  \n",
              "16                        1615  \n",
              "17                         121  \n",
              "18                         878  \n",
              "19                        1560  \n",
              "20                          18  \n",
              "21                         776  \n",
              "22                        2288  \n",
              "23                         597  \n",
              "24                         471  \n",
              "\n",
              "[25 rows x 82 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-403abb4a-836e-4f73-b2bc-c547c9667d3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Beneficiaries_with_A_and_B</th>\n",
              "      <th>Fee_for_service_beneficiaries</th>\n",
              "      <th>Med_Advantage_Count</th>\n",
              "      <th>Med_Advantage_Rate</th>\n",
              "      <th>Average_Age</th>\n",
              "      <th>%Female</th>\n",
              "      <th>%Male</th>\n",
              "      <th>%White</th>\n",
              "      <th>%Black</th>\n",
              "      <th>%Hispanic</th>\n",
              "      <th>...</th>\n",
              "      <th>Dialysis_User_Count</th>\n",
              "      <th>Dialysis_User_%</th>\n",
              "      <th>Dialysis_Visits_Per_1000_Users</th>\n",
              "      <th>FQHC_Std_Costs</th>\n",
              "      <th>FQHC_Std_As_%Total</th>\n",
              "      <th>FQHC_Std_Per_Capita</th>\n",
              "      <th>FQHC_Std_Per_User</th>\n",
              "      <th>FQHC_User_Count</th>\n",
              "      <th>FQHC_User_%</th>\n",
              "      <th>FQHC_Visits_Per_1000_Users</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6444</td>\n",
              "      <td>6186</td>\n",
              "      <td>258</td>\n",
              "      <td>0.0400</td>\n",
              "      <td>71</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.4856</td>\n",
              "      <td>0.8810</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0833</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>741</td>\n",
              "      <td>330449.22</td>\n",
              "      <td>0.0068</td>\n",
              "      <td>53.42</td>\n",
              "      <td>306.26</td>\n",
              "      <td>1079</td>\n",
              "      <td>0.1744</td>\n",
              "      <td>553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7463</td>\n",
              "      <td>6861</td>\n",
              "      <td>602</td>\n",
              "      <td>0.0807</td>\n",
              "      <td>73</td>\n",
              "      <td>0.5270</td>\n",
              "      <td>0.4730</td>\n",
              "      <td>0.9469</td>\n",
              "      <td>0.0020</td>\n",
              "      <td>0.0144</td>\n",
              "      <td>...</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>437</td>\n",
              "      <td>37418.97</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>5.45</td>\n",
              "      <td>558.49</td>\n",
              "      <td>67</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14583</td>\n",
              "      <td>13311</td>\n",
              "      <td>1272</td>\n",
              "      <td>0.0872</td>\n",
              "      <td>71</td>\n",
              "      <td>0.5330</td>\n",
              "      <td>0.4670</td>\n",
              "      <td>0.9246</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0336</td>\n",
              "      <td>...</td>\n",
              "      <td>74</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>665</td>\n",
              "      <td>1257134.97</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>94.44</td>\n",
              "      <td>554.54</td>\n",
              "      <td>2267</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18984</td>\n",
              "      <td>17907</td>\n",
              "      <td>1077</td>\n",
              "      <td>0.0567</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5456</td>\n",
              "      <td>0.4544</td>\n",
              "      <td>0.8645</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0782</td>\n",
              "      <td>...</td>\n",
              "      <td>86</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>554</td>\n",
              "      <td>1058899.69</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>59.13</td>\n",
              "      <td>605.43</td>\n",
              "      <td>1749</td>\n",
              "      <td>0.0977</td>\n",
              "      <td>387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6134</td>\n",
              "      <td>5925</td>\n",
              "      <td>209</td>\n",
              "      <td>0.0341</td>\n",
              "      <td>70</td>\n",
              "      <td>0.5232</td>\n",
              "      <td>0.4768</td>\n",
              "      <td>0.9391</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>0.0253</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>0.0064</td>\n",
              "      <td>659</td>\n",
              "      <td>69716.25</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>11.77</td>\n",
              "      <td>400.67</td>\n",
              "      <td>174</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5256</td>\n",
              "      <td>4734</td>\n",
              "      <td>522</td>\n",
              "      <td>0.0993</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5239</td>\n",
              "      <td>0.4761</td>\n",
              "      <td>0.8925</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>...</td>\n",
              "      <td>18</td>\n",
              "      <td>0.0038</td>\n",
              "      <td>481</td>\n",
              "      <td>111911.30</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>23.64</td>\n",
              "      <td>592.12</td>\n",
              "      <td>189</td>\n",
              "      <td>0.0399</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100102</td>\n",
              "      <td>93339</td>\n",
              "      <td>6763</td>\n",
              "      <td>0.0676</td>\n",
              "      <td>74</td>\n",
              "      <td>0.5273</td>\n",
              "      <td>0.4727</td>\n",
              "      <td>0.9182</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0373</td>\n",
              "      <td>...</td>\n",
              "      <td>247</td>\n",
              "      <td>0.0026</td>\n",
              "      <td>327</td>\n",
              "      <td>10000026.42</td>\n",
              "      <td>0.0122</td>\n",
              "      <td>107.14</td>\n",
              "      <td>625.00</td>\n",
              "      <td>16000</td>\n",
              "      <td>0.1714</td>\n",
              "      <td>652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11777</td>\n",
              "      <td>10945</td>\n",
              "      <td>832</td>\n",
              "      <td>0.0706</td>\n",
              "      <td>52</td>\n",
              "      <td>0.4838</td>\n",
              "      <td>0.5162</td>\n",
              "      <td>0.8429</td>\n",
              "      <td>0.0170</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>...</td>\n",
              "      <td>209</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>2238</td>\n",
              "      <td>1870255.00</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>170.88</td>\n",
              "      <td>704.69</td>\n",
              "      <td>2654</td>\n",
              "      <td>0.2425</td>\n",
              "      <td>1164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>111879</td>\n",
              "      <td>104284</td>\n",
              "      <td>7595</td>\n",
              "      <td>0.0679</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5227</td>\n",
              "      <td>0.4773</td>\n",
              "      <td>0.9103</td>\n",
              "      <td>0.0053</td>\n",
              "      <td>0.0412</td>\n",
              "      <td>...</td>\n",
              "      <td>456</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>527</td>\n",
              "      <td>11870281.41</td>\n",
              "      <td>0.0127</td>\n",
              "      <td>113.83</td>\n",
              "      <td>636.34</td>\n",
              "      <td>18654</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6065</td>\n",
              "      <td>2703</td>\n",
              "      <td>3362</td>\n",
              "      <td>0.5543</td>\n",
              "      <td>67</td>\n",
              "      <td>0.4639</td>\n",
              "      <td>0.5361</td>\n",
              "      <td>0.9811</td>\n",
              "      <td>0.0070</td>\n",
              "      <td>0.0041</td>\n",
              "      <td>...</td>\n",
              "      <td>29</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>1118</td>\n",
              "      <td>1023021.51</td>\n",
              "      <td>0.0388</td>\n",
              "      <td>378.48</td>\n",
              "      <td>596.86</td>\n",
              "      <td>1714</td>\n",
              "      <td>0.6341</td>\n",
              "      <td>4074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>21767</td>\n",
              "      <td>13018</td>\n",
              "      <td>8749</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>71</td>\n",
              "      <td>0.5380</td>\n",
              "      <td>0.4620</td>\n",
              "      <td>0.9694</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>...</td>\n",
              "      <td>71</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>723</td>\n",
              "      <td>397691.08</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>30.55</td>\n",
              "      <td>467.32</td>\n",
              "      <td>851</td>\n",
              "      <td>0.0654</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3549</td>\n",
              "      <td>2056</td>\n",
              "      <td>1493</td>\n",
              "      <td>0.4207</td>\n",
              "      <td>71</td>\n",
              "      <td>0.5233</td>\n",
              "      <td>0.4767</td>\n",
              "      <td>0.9747</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>...</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>754</td>\n",
              "      <td>861028.35</td>\n",
              "      <td>0.0420</td>\n",
              "      <td>418.79</td>\n",
              "      <td>702.31</td>\n",
              "      <td>1226</td>\n",
              "      <td>0.5963</td>\n",
              "      <td>3121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>19330</td>\n",
              "      <td>10717</td>\n",
              "      <td>8613</td>\n",
              "      <td>0.4456</td>\n",
              "      <td>70</td>\n",
              "      <td>0.5289</td>\n",
              "      <td>0.4711</td>\n",
              "      <td>0.9244</td>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>...</td>\n",
              "      <td>80</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>834</td>\n",
              "      <td>2629192.73</td>\n",
              "      <td>0.0236</td>\n",
              "      <td>245.33</td>\n",
              "      <td>526.68</td>\n",
              "      <td>4992</td>\n",
              "      <td>0.4658</td>\n",
              "      <td>1754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>12533</td>\n",
              "      <td>6169</td>\n",
              "      <td>6364</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>71</td>\n",
              "      <td>0.5325</td>\n",
              "      <td>0.4675</td>\n",
              "      <td>0.9752</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>...</td>\n",
              "      <td>59</td>\n",
              "      <td>0.0096</td>\n",
              "      <td>1071</td>\n",
              "      <td>622392.29</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>100.89</td>\n",
              "      <td>543.10</td>\n",
              "      <td>1146</td>\n",
              "      <td>0.1858</td>\n",
              "      <td>737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>7733</td>\n",
              "      <td>4262</td>\n",
              "      <td>3471</td>\n",
              "      <td>0.4489</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5178</td>\n",
              "      <td>0.4822</td>\n",
              "      <td>0.9763</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>...</td>\n",
              "      <td>30</td>\n",
              "      <td>0.0070</td>\n",
              "      <td>954</td>\n",
              "      <td>251256.47</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>58.95</td>\n",
              "      <td>483.19</td>\n",
              "      <td>520</td>\n",
              "      <td>0.1220</td>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10078</td>\n",
              "      <td>4869</td>\n",
              "      <td>5209</td>\n",
              "      <td>0.5169</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5371</td>\n",
              "      <td>0.4629</td>\n",
              "      <td>0.9417</td>\n",
              "      <td>0.0253</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>...</td>\n",
              "      <td>27</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>564</td>\n",
              "      <td>9917.93</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>2.04</td>\n",
              "      <td>413.25</td>\n",
              "      <td>24</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4638</td>\n",
              "      <td>3032</td>\n",
              "      <td>1606</td>\n",
              "      <td>0.3463</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5310</td>\n",
              "      <td>0.4690</td>\n",
              "      <td>0.9631</td>\n",
              "      <td>0.0053</td>\n",
              "      <td>0.0059</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>570</td>\n",
              "      <td>718254.67</td>\n",
              "      <td>0.0264</td>\n",
              "      <td>236.89</td>\n",
              "      <td>680.81</td>\n",
              "      <td>1055</td>\n",
              "      <td>0.3480</td>\n",
              "      <td>1615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>14132</td>\n",
              "      <td>6932</td>\n",
              "      <td>7200</td>\n",
              "      <td>0.5095</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5365</td>\n",
              "      <td>0.4635</td>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.0238</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>...</td>\n",
              "      <td>44</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>762</td>\n",
              "      <td>114978.65</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>16.59</td>\n",
              "      <td>438.85</td>\n",
              "      <td>262</td>\n",
              "      <td>0.0378</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6909</td>\n",
              "      <td>4838</td>\n",
              "      <td>2071</td>\n",
              "      <td>0.2998</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5308</td>\n",
              "      <td>0.4692</td>\n",
              "      <td>0.9554</td>\n",
              "      <td>0.0263</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0041</td>\n",
              "      <td>398</td>\n",
              "      <td>692218.57</td>\n",
              "      <td>0.0132</td>\n",
              "      <td>143.08</td>\n",
              "      <td>573.50</td>\n",
              "      <td>1207</td>\n",
              "      <td>0.2495</td>\n",
              "      <td>878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>16186</td>\n",
              "      <td>8377</td>\n",
              "      <td>7809</td>\n",
              "      <td>0.4825</td>\n",
              "      <td>70</td>\n",
              "      <td>0.5275</td>\n",
              "      <td>0.4725</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>0.0464</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>...</td>\n",
              "      <td>68</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>929</td>\n",
              "      <td>1651757.50</td>\n",
              "      <td>0.0206</td>\n",
              "      <td>197.18</td>\n",
              "      <td>484.81</td>\n",
              "      <td>3407</td>\n",
              "      <td>0.4067</td>\n",
              "      <td>1560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>7742</td>\n",
              "      <td>3280</td>\n",
              "      <td>4462</td>\n",
              "      <td>0.5763</td>\n",
              "      <td>71</td>\n",
              "      <td>0.5345</td>\n",
              "      <td>0.4655</td>\n",
              "      <td>0.9759</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>...</td>\n",
              "      <td>17</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>744</td>\n",
              "      <td>8027.65</td>\n",
              "      <td>0.0002</td>\n",
              "      <td>2.45</td>\n",
              "      <td>334.49</td>\n",
              "      <td>24</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>12759</td>\n",
              "      <td>6528</td>\n",
              "      <td>6231</td>\n",
              "      <td>0.4884</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5415</td>\n",
              "      <td>0.4585</td>\n",
              "      <td>0.9521</td>\n",
              "      <td>0.0268</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>...</td>\n",
              "      <td>57</td>\n",
              "      <td>0.0087</td>\n",
              "      <td>1183</td>\n",
              "      <td>647465.25</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>99.18</td>\n",
              "      <td>554.34</td>\n",
              "      <td>1168</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>8830</td>\n",
              "      <td>4072</td>\n",
              "      <td>4758</td>\n",
              "      <td>0.5388</td>\n",
              "      <td>67</td>\n",
              "      <td>0.5091</td>\n",
              "      <td>0.4909</td>\n",
              "      <td>0.9683</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>818</td>\n",
              "      <td>1106000.31</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>271.61</td>\n",
              "      <td>637.46</td>\n",
              "      <td>1735</td>\n",
              "      <td>0.4261</td>\n",
              "      <td>2288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>44755</td>\n",
              "      <td>21446</td>\n",
              "      <td>23309</td>\n",
              "      <td>0.5208</td>\n",
              "      <td>71</td>\n",
              "      <td>0.5356</td>\n",
              "      <td>0.4644</td>\n",
              "      <td>0.9225</td>\n",
              "      <td>0.0512</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>...</td>\n",
              "      <td>180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>933</td>\n",
              "      <td>1809829.18</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>84.39</td>\n",
              "      <td>504.27</td>\n",
              "      <td>3589</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>10474</td>\n",
              "      <td>6856</td>\n",
              "      <td>3618</td>\n",
              "      <td>0.3454</td>\n",
              "      <td>72</td>\n",
              "      <td>0.5492</td>\n",
              "      <td>0.4508</td>\n",
              "      <td>0.8995</td>\n",
              "      <td>0.0521</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>...</td>\n",
              "      <td>65</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>1200</td>\n",
              "      <td>288231.62</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>42.04</td>\n",
              "      <td>292.32</td>\n",
              "      <td>986</td>\n",
              "      <td>0.1438</td>\n",
              "      <td>471</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25 rows Ã— 82 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-403abb4a-836e-4f73-b2bc-c547c9667d3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-403abb4a-836e-4f73-b2bc-c547c9667d3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-403abb4a-836e-4f73-b2bc-c547c9667d3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check out data types\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY5DWy-xzxvh",
        "outputId": "6c7381d2-320c-4d3a-9dce-f7b023d9f65f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17749 entries, 0 to 17748\n",
            "Data columns (total 82 columns):\n",
            " #   Column                                       Non-Null Count  Dtype  \n",
            "---  ------                                       --------------  -----  \n",
            " 0   Beneficiaries_with_A_and_B                   17749 non-null  int64  \n",
            " 1   Fee_for_service_beneficiaries                17749 non-null  int64  \n",
            " 2   Med_Advantage_Count                          17749 non-null  int64  \n",
            " 3   Med_Advantage_Rate                           17749 non-null  float64\n",
            " 4   Average_Age                                  17749 non-null  int64  \n",
            " 5   %Female                                      17749 non-null  float64\n",
            " 6   %Male                                        17749 non-null  float64\n",
            " 7   %White                                       17749 non-null  float64\n",
            " 8   %Black                                       17749 non-null  float64\n",
            " 9   %Hispanic                                    17749 non-null  float64\n",
            " 10  %OtherRace                                   17749 non-null  float64\n",
            " 11  %Dual_Eligible                               17749 non-null  float64\n",
            " 12  Avg_Risk_Score                               17749 non-null  float64\n",
            " 13  Total_Standardized_Costs                     17749 non-null  float64\n",
            " 14  Total_Std_Risk_Adjusted_Costs                17749 non-null  float64\n",
            " 15  Standardized_Per_Capita_Costs                17749 non-null  float64\n",
            " 16  Standardized_Risk_Adjusted_Per_Capita_Costs  17749 non-null  float64\n",
            " 17  IP_Standardized_Costs                        17749 non-null  float64\n",
            " 18  IP_Std_%Total                                17749 non-null  float64\n",
            " 19  IP_Std_Per_Capita                            17749 non-null  float64\n",
            " 20  IP_Std_Per_User                              17749 non-null  float64\n",
            " 21  IP_Users                                     17749 non-null  int64  \n",
            " 22  %Beneficiaries_Using_IP                      17749 non-null  float64\n",
            " 23  IP_Covered_Stays_Per_1000                    17749 non-null  int64  \n",
            " 24  IP_Covered_Days_Per_1000                     17749 non-null  int64  \n",
            " 25  Hospital_Readmit_Count                       17749 non-null  int64  \n",
            " 26  Hospital_Readmit_Rate%                       17749 non-null  float64\n",
            " 27  ER_Visits_Count                              17749 non-null  int64  \n",
            " 28  ER_Visits_Per_1000                           17749 non-null  int64  \n",
            " 29  %ER_Visits                                   17749 non-null  float64\n",
            " 30  OP_Std_Costs                                 17749 non-null  float64\n",
            " 31  OP_Std_%Total                                17749 non-null  float64\n",
            " 32  OP_Std_Per_Capita_Costs                      17749 non-null  float64\n",
            " 33  OP_Std_Per_User_Costs                        17749 non-null  float64\n",
            " 34  OP_Users_Count                               17749 non-null  int64  \n",
            " 35  %_Using_OP                                   17749 non-null  float64\n",
            " 36  OP_Visits_Per_1000                           17749 non-null  int64  \n",
            " 37  SNF_Std_Costs                                17749 non-null  float64\n",
            " 38  SNF_Std_As_%Total                            17749 non-null  float64\n",
            " 39  SNF_Std_Per_Capita                           17749 non-null  float64\n",
            " 40  SNF_Std_Per_User                             17749 non-null  float64\n",
            " 41  SNF_Users_Count                              17749 non-null  int64  \n",
            " 42  SNF_Users_%Beneficiaries                     17749 non-null  float64\n",
            " 43  SNF_Per_1000_Users                           17749 non-null  int64  \n",
            " 44  SNF_Days_Per_1000_Users                      17749 non-null  int64  \n",
            " 45  HH_Std_Costs                                 17749 non-null  float64\n",
            " 46  HH_Std_As_%Total                             17749 non-null  float64\n",
            " 47  HH_Std_Per_Capita                            17749 non-null  float64\n",
            " 48  HH_Std_Per_User                              17749 non-null  float64\n",
            " 49  HH_User_Count                                17749 non-null  int64  \n",
            " 50  HH_User_Percent                              17749 non-null  float64\n",
            " 51  HH_Per_1000_Users                            17749 non-null  int64  \n",
            " 52  HH_Visits_Per_1000_Users                     17749 non-null  int64  \n",
            " 53  Hospice_Std_Costs                            17749 non-null  float64\n",
            " 54  Hospice_Std_As_%Total                        17749 non-null  float64\n",
            " 55  Hospice_Std_Per_Capita                       17749 non-null  float64\n",
            " 56  Hospice_Std_Per_User                         17749 non-null  float64\n",
            " 57  Hospice_Count                                17749 non-null  int64  \n",
            " 58  Hospice_%                                    17749 non-null  float64\n",
            " 59  Hospice_Per_1000_Users                       17749 non-null  int64  \n",
            " 60  Hospice_Days_Per_1000_Users                  17749 non-null  int64  \n",
            " 61  EM_Std_Costs                                 17749 non-null  float64\n",
            " 62  EM_Std_As_%Total                             17749 non-null  float64\n",
            " 63  EM_Std_Per_Capita                            17749 non-null  float64\n",
            " 64  EM_Std_Per_User                              17749 non-null  float64\n",
            " 65  EM_User_Count                                17749 non-null  int64  \n",
            " 66  EM_User_%                                    17749 non-null  float64\n",
            " 67  EM_Events_Per_1000_Users                     17749 non-null  int64  \n",
            " 68  Dialysis_Std_Costs                           17749 non-null  float64\n",
            " 69  Dialysis_Std_As_%Total                       17749 non-null  float64\n",
            " 70  Dialysis_Std_Per_Capita                      17749 non-null  float64\n",
            " 71  Dialysis_Std_Per_User                        17749 non-null  float64\n",
            " 72  Dialysis_User_Count                          17749 non-null  int64  \n",
            " 73  Dialysis_User_%                              17749 non-null  float64\n",
            " 74  Dialysis_Visits_Per_1000_Users               17749 non-null  int64  \n",
            " 75  FQHC_Std_Costs                               17749 non-null  float64\n",
            " 76  FQHC_Std_As_%Total                           17749 non-null  float64\n",
            " 77  FQHC_Std_Per_Capita                          17749 non-null  float64\n",
            " 78  FQHC_Std_Per_User                            17749 non-null  float64\n",
            " 79  FQHC_User_Count                              17749 non-null  int64  \n",
            " 80  FQHC_User_%                                  17749 non-null  float64\n",
            " 81  FQHC_Visits_Per_1000_Users                   17749 non-null  int64  \n",
            "dtypes: float64(55), int64(27)\n",
            "memory usage: 11.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readmit_count=df['Hospital_Readmit_Rate%'].value_counts()\n",
        "readmit_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBsSKKtobaAt",
        "outputId": "1fe70334-8ae8-4752-ff48-80642f4658c5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1703    51\n",
              "0.1667    48\n",
              "0.1767    46\n",
              "0.1776    43\n",
              "0.1720    43\n",
              "          ..\n",
              "0.0936     1\n",
              "0.2480     1\n",
              "0.2482     1\n",
              "0.2769     1\n",
              "0.2288     1\n",
              "Name: Hospital_Readmit_Rate%, Length: 1427, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split preprocessed data into features and target arrays\n",
        "X=df.drop(['Hospital_Readmit_Rate%'], axis=1).values\n",
        "y=df['Hospital_Readmit_Rate%'].values\n",
        "\n",
        "# Split preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test=train_test_split(X,y, random_state=3)"
      ],
      "metadata": {
        "id": "7-mMSwJqGijR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "xv4Dt4WZMjuB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the shape\n",
        "X_train_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqWzdI_DMtoQ",
        "outputId": "116da58d-cf1e-4954-9de2-65060b7c7226"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13311, 81)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = X_train_scaled.shape[1]"
      ],
      "metadata": {
        "id": "iyb5oSx2MyfG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwCZ-nK9M1fg",
        "outputId": "045369fb-16a4-45dc-96e0-12043975e083"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create function to allow kerastuner to decide which activation functions, neurons, and hidden layers optimize output\n",
        "def create_model(hp):\n",
        "    nn = tf.keras.models.Sequential()\n",
        "\n",
        "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
        "    \n",
        "    nn.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
        "        min_value=1,\n",
        "        max_value= 90,\n",
        "        step=5), activation=activation, input_dim=input))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', 1, 5)):\n",
        "        nn.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
        "            min_value=1,\n",
        "            max_value=30,\n",
        "            step=5),\n",
        "            activation=activation))\n",
        "    \n",
        "    nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "    # Compile the model\n",
        "    nn.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
        "    \n",
        "    return nn"
      ],
      "metadata": {
        "id": "g1BI1qFKM6DC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add tuner library\n",
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    create_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_epochs=100,\n",
        "    hyperband_iterations=2)"
      ],
      "metadata": {
        "id": "BON9UZ6RNAWC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the kerastuner \n",
        "tuner.search(X_train_scaled,y_train,epochs=100,validation_data=(X_test_scaled,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "xVyLLHwCNOsi",
        "outputId": "40cafc44-e9ee-474d-ddd4-5a3a088cc9ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 137 Complete [00h 00m 14s]\n",
            "val_accuracy: 0.0\n",
            "\n",
            "Best val_accuracy So Far: 0.0\n",
            "Total elapsed time: 00h 14m 00s\n",
            "\n",
            "Search: Running Trial #138\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "relu              |tanh              |activation\n",
            "66                |86                |first_units\n",
            "2                 |3                 |num_layers\n",
            "26                |6                 |units_0\n",
            "1                 |1                 |units_1\n",
            "1                 |1                 |units_2\n",
            "6                 |None              |units_3\n",
            "26                |None              |units_4\n",
            "12                |2                 |tuner/epochs\n",
            "4                 |0                 |tuner/initial_epoch\n",
            "4                 |4                 |tuner/bracket\n",
            "2                 |0                 |tuner/round\n",
            "0104              |None              |tuner/trial_id\n",
            "\n",
            "Epoch 5/12\n",
            "416/416 [==============================] - 2s 3ms/step - loss: 0.5053 - accuracy: 0.0000e+00 - val_loss: 0.4904 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/12\n",
            "416/416 [==============================] - 1s 3ms/step - loss: 0.4810 - accuracy: 0.0000e+00 - val_loss: 0.4736 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/12\n",
            "416/416 [==============================] - 1s 3ms/step - loss: 0.4692 - accuracy: 0.0000e+00 - val_loss: 0.4660 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/12\n",
            "416/416 [==============================] - 1s 3ms/step - loss: 0.4641 - accuracy: 0.0000e+00 - val_loss: 0.4630 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/12\n",
            "416/416 [==============================] - 1s 3ms/step - loss: 0.4623 - accuracy: 0.0000e+00 - val_loss: 0.4620 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/12\n",
            "400/416 [===========================>..] - ETA: 0s - loss: 0.4617 - accuracy: 0.0000e+00"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1f5a3809cb66>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the kerastuner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    216\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                         )\n\u001b[0;32m-> 1729\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2065\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2067\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2068\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[1;32m   2069\u001b[0m                             \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m             \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             can_run_full_execution = (\n\u001b[1;32m   1377\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    649\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mread_value_no_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4091\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4092\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4093\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   4094\u001b[0m         _ctx, \"Identity\", name, input)\n\u001b[1;32m   4095\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bSNDkagFNTAU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}